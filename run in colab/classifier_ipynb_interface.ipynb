{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "classifier_ipynb_interface.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmnU_3lyZxjO"
      },
      "source": [
        "# **How to Use the classificator:**\r\n",
        "\r\n",
        "**- connect to a Colab GPU runtime**\r\n",
        "\r\n",
        "**- upload the newest version of \"pytorchVERSIONNUMBERX.zip\" to the \"content\" folder of the runtime**\r\n",
        "\r\n",
        "**- configure the networkmode according to your needs in the execution cell**\r\n",
        "\r\n",
        "**- run notebook**\r\n",
        "\r\n",
        "***use the last cell, if you have made changes to the classificator you would like to save for another session!!!***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks5yyBOYMnSr"
      },
      "source": [
        "!unzip \"/content/pytorch57.zip\" -d \"/content/dgcnn/\"\r\n",
        "\r\n",
        "%cd dgcnn/pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icdR6oigPP06",
        "outputId": "83c56550-4de2-477b-a2c4-128925d81807"
      },
      "source": [
        "#%cd dgcnn/pytorch\r\n",
        "\r\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoints  data     ftdat    model.py  pretrained  singfpass.py  util.py\n",
            "classfiles   data.py  main.py  output\t README.md   to_classify\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuQXbenZOKy3",
        "outputId": "dfbaa3c9-6e2f-4ec8-bdcb-b656330f5129"
      },
      "source": [
        "# Additional Network Modes:\r\n",
        "#--classifymixed:     load the ModelNet40 pretrained model and classify/ annotate objects based on that\r\n",
        "#--classifycustom:    load the custom model thats trained with the custom dataset from ftdat and classify/ annotate objects based on that\r\n",
        "#--customtrain:       train a DGCNN with the custom dataset from ftdat\r\n",
        "#--evalmixedperf:     evaluate the performance of the pretrainded ModelNet40 model on custom data from ftdat\r\n",
        "#--evalcustomperf:    evaluate the performance of the custom trained model on custom data from ftdat\r\n",
        "\r\n",
        "\r\n",
        "!python3 main.py --exp_name=dgcnn_1024 --model=dgcnn --num_points=1024 --k=20 --epochs=50 --use_sgd=True --test_batch_size=32 --customtrain --evalcustomperf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(batch_size=32, classify_mode_custom=False, classify_mode_mixed=False, dataset='modelnet40', dropout=0.5, emb_dims=1024, epochs=50, eval=False, eval_custom=True, eval_mixed=False, exp_name='dgcnn_1024', k=20, lr=0.001, model='dgcnn', model_path='', momentum=0.9, no_cuda=False, num_points=1024, seed=1, test_batch_size=32, train_custom=True, use_sgd=True)\n",
            "Using GPU : 0 from 1 devices\n",
            "Namespace(batch_size=32, classify_mode_custom=False, classify_mode_mixed=False, cuda=True, dataset='modelnet40', dropout=0.5, emb_dims=1024, epochs=50, eval=False, eval_custom=True, eval_mixed=False, exp_name='dgcnn_1024', k=20, lr=0.001, model='dgcnn', model_path='', momentum=0.9, no_cuda=False, num_points=1024, seed=1, test_batch_size=32, train_custom=True, use_sgd=True)\n",
            "['14', '33', '22', '2', '8', '35', '12', '30', '23', '1']\n",
            "/content/dgcnn/pytorch/ftdat/dset/14\n",
            "/content/dgcnn/pytorch/ftdat/dset/33\n",
            "/content/dgcnn/pytorch/ftdat/dset/22\n",
            "/content/dgcnn/pytorch/ftdat/dset/2\n",
            "/content/dgcnn/pytorch/ftdat/dset/8\n",
            "/content/dgcnn/pytorch/ftdat/dset/35\n",
            "/content/dgcnn/pytorch/ftdat/dset/12\n",
            "/content/dgcnn/pytorch/ftdat/dset/30\n",
            "/content/dgcnn/pytorch/ftdat/dset/23\n",
            "/content/dgcnn/pytorch/ftdat/dset/1\n",
            "all data loaded! torch.Size([10010, 2048, 3])\n",
            "all labels loaded! torch.Size([10010])\n",
            "tensor([14, 14, 14,  ...,  1,  1,  1])\n",
            "['14', '33', '22', '2', '8', '35', '12', '30', '23', '1']\n",
            "/content/dgcnn/pytorch/ftdat/valdset/14\n",
            "/content/dgcnn/pytorch/ftdat/valdset/33\n",
            "/content/dgcnn/pytorch/ftdat/valdset/22\n",
            "/content/dgcnn/pytorch/ftdat/valdset/2\n",
            "/content/dgcnn/pytorch/ftdat/valdset/8\n",
            "/content/dgcnn/pytorch/ftdat/valdset/35\n",
            "/content/dgcnn/pytorch/ftdat/valdset/12\n",
            "/content/dgcnn/pytorch/ftdat/valdset/30\n",
            "/content/dgcnn/pytorch/ftdat/valdset/23\n",
            "/content/dgcnn/pytorch/ftdat/valdset/1\n",
            "all data loaded! torch.Size([908, 2048, 3])\n",
            "all labels loaded! torch.Size([908])\n",
            "tensor([14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 33, 33, 33, 33,\n",
            "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
            "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
            "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
            "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
            "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
            "        33, 33, 33, 33, 33, 33, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
            "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
            "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
            "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
            "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
            "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,  2,  2,\n",
            "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
            "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
            "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
            "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
            "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
            "         2,  2,  2,  2,  2,  2,  2,  2,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
            "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
            "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
            "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
            "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
            "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
            "        35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
            "        35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
            "        35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
            "        35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
            "        35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
            "        35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 12, 12, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
            "        30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
            "        30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
            "        30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
            "        30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
            "        30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 23, 23,\n",
            "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
            "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
            "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
            "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
            "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,  1,  1,  1,  1,  1,  1,\n",
            "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "         1,  1,  1,  1,  1,  1,  1,  1])\n",
            "DGCNN(\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(6, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (conv5): Sequential(\n",
            "    (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (linear1): Linear(in_features=2048, out_features=512, bias=False)\n",
            "  (bn6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dp1): Dropout(p=0.5, inplace=False)\n",
            "  (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (bn7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dp2): Dropout(p=0.5, inplace=False)\n",
            "  (linear3): Linear(in_features=256, out_features=40, bias=True)\n",
            ")\n",
            "Let's use 1 GPUs!\n",
            "Use SGD\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn('y_pred contains classes not in y_true')\n",
            "Train 0, loss: 2.427179, train acc: 0.477163, train avg acc: 0.477038\n",
            "Test 0, loss: 1.852772, test acc: 0.716960, test avg acc: 0.726047\n",
            "save now\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 1, loss: 1.865016, train acc: 0.714844, train avg acc: 0.714702\n",
            "Test 1, loss: 1.774312, test acc: 0.757709, test avg acc: 0.757163\n",
            "save now\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 2, loss: 1.742490, train acc: 0.775040, train avg acc: 0.774884\n",
            "Test 2, loss: 1.600723, test acc: 0.833700, test avg acc: 0.826488\n",
            "save now\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 3, loss: 1.677434, train acc: 0.813602, train avg acc: 0.813563\n",
            "Test 3, loss: 1.705351, test acc: 0.802863, test avg acc: 0.800814\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 4, loss: 1.643514, train acc: 0.826923, train avg acc: 0.826804\n",
            "Test 4, loss: 1.561030, test acc: 0.867841, test avg acc: 0.863116\n",
            "save now\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 5, loss: 1.617247, train acc: 0.837340, train avg acc: 0.837172\n",
            "Test 5, loss: 1.569498, test acc: 0.854626, test avg acc: 0.844814\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 6, loss: 1.599405, train acc: 0.845453, train avg acc: 0.845310\n",
            "Test 6, loss: 1.562323, test acc: 0.868943, test avg acc: 0.862302\n",
            "save now\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 7, loss: 1.578029, train acc: 0.858874, train avg acc: 0.858806\n",
            "Test 7, loss: 1.642220, test acc: 0.851322, test avg acc: 0.849465\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 8, loss: 1.561818, train acc: 0.867488, train avg acc: 0.867407\n",
            "Test 8, loss: 1.497663, test acc: 0.882159, test avg acc: 0.875953\n",
            "save now\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 9, loss: 1.542403, train acc: 0.875401, train avg acc: 0.875322\n",
            "Test 9, loss: 1.514824, test acc: 0.884361, test avg acc: 0.875605\n",
            "save now\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 10, loss: 1.534480, train acc: 0.880008, train avg acc: 0.879920\n",
            "Test 10, loss: 1.488431, test acc: 0.893172, test avg acc: 0.889233\n",
            "save now\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 11, loss: 1.529194, train acc: 0.880909, train avg acc: 0.880800\n",
            "Test 11, loss: 1.494467, test acc: 0.893172, test avg acc: 0.889628\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 12, loss: 1.516549, train acc: 0.888922, train avg acc: 0.888897\n",
            "Test 12, loss: 1.495043, test acc: 0.882159, test avg acc: 0.880070\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 13, loss: 1.499666, train acc: 0.897837, train avg acc: 0.897831\n",
            "Test 13, loss: 1.481280, test acc: 0.903084, test avg acc: 0.903186\n",
            "save now\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 14, loss: 1.488861, train acc: 0.901042, train avg acc: 0.901010\n",
            "Test 14, loss: 1.444037, test acc: 0.912996, test avg acc: 0.911047\n",
            "save now\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 15, loss: 1.483519, train acc: 0.906651, train avg acc: 0.906623\n",
            "Test 15, loss: 1.575561, test acc: 0.846916, test avg acc: 0.845628\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 16, loss: 1.481035, train acc: 0.908654, train avg acc: 0.908574\n",
            "Test 16, loss: 1.466062, test acc: 0.894273, test avg acc: 0.892721\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 17, loss: 1.468321, train acc: 0.913562, train avg acc: 0.913516\n",
            "Test 17, loss: 1.558786, test acc: 0.872247, test avg acc: 0.872442\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 18, loss: 1.460155, train acc: 0.916266, train avg acc: 0.916265\n",
            "Test 18, loss: 1.471552, test acc: 0.903084, test avg acc: 0.900860\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 19, loss: 1.448122, train acc: 0.926382, train avg acc: 0.926311\n",
            "Test 19, loss: 1.486801, test acc: 0.903084, test avg acc: 0.903209\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 20, loss: 1.453714, train acc: 0.921174, train avg acc: 0.921098\n",
            "Test 20, loss: 1.452531, test acc: 0.911894, test avg acc: 0.912326\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 21, loss: 1.437015, train acc: 0.931090, train avg acc: 0.931021\n",
            "Test 21, loss: 1.565495, test acc: 0.868943, test avg acc: 0.866488\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 22, loss: 1.433347, train acc: 0.929087, train avg acc: 0.928999\n",
            "Test 22, loss: 1.443433, test acc: 0.919604, test avg acc: 0.916698\n",
            "save now\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 23, loss: 1.423342, train acc: 0.935797, train avg acc: 0.935722\n",
            "Test 23, loss: 1.471715, test acc: 0.900881, test avg acc: 0.898744\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 24, loss: 1.420523, train acc: 0.936799, train avg acc: 0.936774\n",
            "Test 24, loss: 1.505610, test acc: 0.894273, test avg acc: 0.892256\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 25, loss: 1.414519, train acc: 0.939804, train avg acc: 0.939782\n",
            "Test 25, loss: 1.489113, test acc: 0.904185, test avg acc: 0.902535\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 26, loss: 1.416082, train acc: 0.938602, train avg acc: 0.938588\n",
            "Test 26, loss: 1.461432, test acc: 0.907489, test avg acc: 0.903721\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 27, loss: 1.410111, train acc: 0.938802, train avg acc: 0.938789\n",
            "Test 27, loss: 1.469090, test acc: 0.906388, test avg acc: 0.903558\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 28, loss: 1.400203, train acc: 0.946715, train avg acc: 0.946659\n",
            "Test 28, loss: 1.460274, test acc: 0.910793, test avg acc: 0.909837\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 29, loss: 1.394875, train acc: 0.948017, train avg acc: 0.947994\n",
            "Test 29, loss: 1.454311, test acc: 0.909692, test avg acc: 0.908372\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 30, loss: 1.392057, train acc: 0.949720, train avg acc: 0.949645\n",
            "Test 30, loss: 1.440286, test acc: 0.916300, test avg acc: 0.915349\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 31, loss: 1.387746, train acc: 0.952224, train avg acc: 0.952164\n",
            "Test 31, loss: 1.483241, test acc: 0.901982, test avg acc: 0.898744\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 32, loss: 1.377752, train acc: 0.958534, train avg acc: 0.958473\n",
            "Test 32, loss: 1.443259, test acc: 0.916300, test avg acc: 0.914535\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 33, loss: 1.375677, train acc: 0.957131, train avg acc: 0.957097\n",
            "Test 33, loss: 1.458189, test acc: 0.909692, test avg acc: 0.907884\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 34, loss: 1.370119, train acc: 0.962240, train avg acc: 0.962142\n",
            "Test 34, loss: 1.460156, test acc: 0.911894, test avg acc: 0.909047\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 35, loss: 1.367835, train acc: 0.961939, train avg acc: 0.961892\n",
            "Test 35, loss: 1.444526, test acc: 0.912996, test avg acc: 0.910535\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 36, loss: 1.361784, train acc: 0.964844, train avg acc: 0.964836\n",
            "Test 36, loss: 1.478890, test acc: 0.909692, test avg acc: 0.907233\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 37, loss: 1.364133, train acc: 0.963341, train avg acc: 0.963310\n",
            "Test 37, loss: 1.432378, test acc: 0.917401, test avg acc: 0.916349\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 38, loss: 1.358971, train acc: 0.964643, train avg acc: 0.964630\n",
            "Test 38, loss: 1.441028, test acc: 0.916300, test avg acc: 0.914372\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 39, loss: 1.355982, train acc: 0.965545, train avg acc: 0.965514\n",
            "Test 39, loss: 1.465570, test acc: 0.915198, test avg acc: 0.913372\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 40, loss: 1.353963, train acc: 0.966747, train avg acc: 0.966744\n",
            "Test 40, loss: 1.426084, test acc: 0.921806, test avg acc: 0.920023\n",
            "save now\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 41, loss: 1.351927, train acc: 0.969952, train avg acc: 0.969920\n",
            "Test 41, loss: 1.442288, test acc: 0.916300, test avg acc: 0.914860\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 42, loss: 1.348209, train acc: 0.969351, train avg acc: 0.969331\n",
            "Test 42, loss: 1.441369, test acc: 0.917401, test avg acc: 0.915023\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 43, loss: 1.346635, train acc: 0.970553, train avg acc: 0.970529\n",
            "Test 43, loss: 1.439790, test acc: 0.920705, test avg acc: 0.919186\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 44, loss: 1.345835, train acc: 0.969251, train avg acc: 0.969231\n",
            "Test 44, loss: 1.443182, test acc: 0.917401, test avg acc: 0.916186\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 45, loss: 1.342684, train acc: 0.972256, train avg acc: 0.972216\n",
            "Test 45, loss: 1.447350, test acc: 0.917401, test avg acc: 0.916023\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 46, loss: 1.345226, train acc: 0.970853, train avg acc: 0.970810\n",
            "Test 46, loss: 1.439312, test acc: 0.919604, test avg acc: 0.918186\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 47, loss: 1.341451, train acc: 0.973758, train avg acc: 0.973739\n",
            "Test 47, loss: 1.441790, test acc: 0.920705, test avg acc: 0.919349\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 48, loss: 1.340403, train acc: 0.972356, train avg acc: 0.972351\n",
            "Test 48, loss: 1.438663, test acc: 0.925110, test avg acc: 0.923349\n",
            "save now\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Train 49, loss: 1.342164, train acc: 0.972256, train avg acc: 0.972220\n",
            "Test 49, loss: 1.440873, test acc: 0.921806, test avg acc: 0.920674\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "['14', '33', '22', '2', '8', '35', '12', '30', '23', '1']\n",
            "/content/dgcnn/pytorch/ftdat/valdset/14\n",
            "/content/dgcnn/pytorch/ftdat/valdset/33\n",
            "/content/dgcnn/pytorch/ftdat/valdset/22\n",
            "/content/dgcnn/pytorch/ftdat/valdset/2\n",
            "/content/dgcnn/pytorch/ftdat/valdset/8\n",
            "/content/dgcnn/pytorch/ftdat/valdset/35\n",
            "/content/dgcnn/pytorch/ftdat/valdset/12\n",
            "/content/dgcnn/pytorch/ftdat/valdset/30\n",
            "/content/dgcnn/pytorch/ftdat/valdset/23\n",
            "/content/dgcnn/pytorch/ftdat/valdset/1\n",
            "all data loaded! torch.Size([908, 2048, 3])\n",
            "all labels loaded! torch.Size([908])\n",
            "tensor([14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 33, 33, 33, 33,\n",
            "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
            "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
            "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
            "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
            "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
            "        33, 33, 33, 33, 33, 33, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
            "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
            "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
            "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
            "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
            "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,  2,  2,\n",
            "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
            "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
            "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
            "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
            "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
            "         2,  2,  2,  2,  2,  2,  2,  2,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
            "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
            "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
            "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
            "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
            "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
            "        35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
            "        35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
            "        35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
            "        35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
            "        35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
            "        35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 12, 12, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
            "        30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
            "        30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
            "        30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
            "        30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
            "        30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 23, 23,\n",
            "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
            "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
            "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
            "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
            "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,  1,  1,  1,  1,  1,  1,\n",
            "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "         1,  1,  1,  1,  1,  1,  1,  1])\n",
            "LABELS: tensor([33, 22, 22,  8, 23, 33, 14, 35,  2, 30, 14, 35,  1, 22, 12, 22, 30,  1,\n",
            "        12, 30, 23, 22,  8, 35, 35, 12, 35, 22, 35, 12,  2, 22],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([33, 22, 22,  8, 14, 33, 14, 35,  2, 30, 14, 35,  1, 22, 12, 22, 30,  1,\n",
            "        12, 30, 14, 22,  8, 35, 35, 12, 35, 22, 35, 12,  2, 22],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([35, 35,  8, 33,  1, 12,  2,  2, 33, 22, 14, 30, 35, 35, 14,  2, 14, 30,\n",
            "         1,  1, 35, 23, 33,  8, 35, 22, 23, 14,  8, 30, 23, 12],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([35, 35,  8, 33,  1, 12,  2,  2, 33, 22, 14, 30, 35, 35, 14,  2, 14, 30,\n",
            "         1,  1, 35, 23, 33,  8, 35, 22, 23, 14,  8, 30, 23, 12],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([30,  2, 14, 14, 23, 33,  8,  2, 22, 35, 22, 23,  8, 35,  2, 23,  2, 12,\n",
            "        23, 30, 12, 35, 33,  1, 33,  8,  2, 14, 23, 23, 14,  8],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([30,  2, 14, 14, 23, 33,  8,  2, 22, 35, 22, 23,  8, 35,  2, 23,  2, 12,\n",
            "        14, 30, 12, 35, 12,  1, 33,  8,  2, 14, 23, 23, 14,  8],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([14, 33,  1,  2,  2, 30, 33, 12, 33, 35,  2, 14, 12, 33, 12, 12, 30,  8,\n",
            "        14, 22, 22, 30, 22, 33, 35, 22,  1, 35, 12, 14,  8, 35],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([14, 12,  1,  2,  2, 30, 33, 12, 33, 35,  2, 14, 12, 33, 12, 12, 30,  8,\n",
            "        14, 22, 22, 30, 22, 33, 35, 22,  1, 35, 33, 23,  8, 35],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([23, 23, 33, 35,  1, 35,  8, 23,  8,  8, 22, 22, 35, 14, 30,  1, 35,  1,\n",
            "        33, 35, 33,  8, 35, 35, 33, 23, 35, 30,  8,  2, 14,  2],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([23, 23, 33, 35,  1, 35,  8, 33,  8,  8, 22, 22, 35, 23, 30,  1, 35,  1,\n",
            "        33, 35, 33,  8, 35, 35, 33, 14, 35, 30, 35,  2, 23,  2],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([33, 12, 22, 33, 35,  2, 14,  1, 14, 35, 22, 35, 30, 22, 35,  2, 23, 35,\n",
            "        22, 14, 35, 14, 30, 22, 30, 33,  2, 35, 35,  8, 33, 33],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([33, 12, 22, 33, 35,  2, 23,  1, 14, 35, 22, 35, 30, 22, 35,  2, 23, 35,\n",
            "        22, 14, 35, 14, 30, 22, 30, 33,  2, 35, 35,  8, 12, 33],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([33, 33,  8,  2, 22,  2, 23, 30,  1, 23, 33, 33, 22,  8,  8, 12, 35, 35,\n",
            "        30, 14, 12, 23, 33, 30, 30, 22, 30,  8, 22,  2, 22, 30],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([33, 33,  8,  2, 22,  2, 23, 30,  1, 23, 33, 33, 22,  8,  8, 12, 35, 35,\n",
            "        30, 14, 12, 23, 33, 30, 30, 22, 30,  8, 22,  2, 22, 30],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([22, 22, 33,  8,  8, 12, 33, 14, 12, 23, 30, 14,  8, 23, 35, 22, 14, 30,\n",
            "        35, 23, 33,  8, 12, 23, 12, 23, 23, 35, 14,  8, 22, 14],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([22, 22, 33,  8,  8, 12, 33, 14, 14, 23, 30, 14,  8, 14, 35, 22, 14, 30,\n",
            "        35, 23, 33, 30, 12, 23, 12, 23, 23, 35, 14,  8, 22, 23],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([23, 14, 22, 30,  1, 33,  1, 22, 14, 33, 33, 33,  8,  8, 12, 12, 12, 33,\n",
            "        23, 23, 14, 30,  2, 22, 35, 14, 12, 22,  2, 30,  8,  2],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([ 8, 14, 22, 30,  1, 33,  1, 22, 14, 33, 12, 33,  8,  8, 12, 33, 12, 33,\n",
            "        23, 23, 14, 30,  2, 22, 35, 14, 12, 22,  2, 30,  8,  2],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([ 8,  1,  8,  8,  8, 30, 35,  8, 35, 22,  1, 23, 14,  2,  2,  8, 35, 30,\n",
            "        30,  1,  2,  8, 33, 22,  8, 12,  8, 35, 14,  2, 35,  2],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([ 8,  1,  8,  8,  8, 30, 35,  8, 35, 22,  1, 14, 14,  2,  2,  8, 35, 30,\n",
            "         2,  1,  2,  8, 12, 22,  8, 12,  8, 35, 14,  2, 35,  2],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([12, 14, 35, 22, 23, 30, 22, 33, 33, 23, 35,  8,  1, 23, 14,  8,  8, 12,\n",
            "         8, 30, 14, 12, 12, 35, 14, 33, 33, 35, 12, 23,  8,  2],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([12, 14, 35, 22, 14, 30, 22, 33, 23, 33, 35,  8,  1, 14, 14,  8,  8, 12,\n",
            "         8, 30, 14, 12, 12, 35, 14, 33, 33, 35, 12, 23,  8,  2],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([ 8, 22, 30, 33,  2, 12, 22,  2, 33, 30, 12,  8,  8, 14, 22, 35, 35,  2,\n",
            "         8,  2,  1, 30, 22,  2, 33, 35, 30, 12, 33,  8, 14, 14],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([ 8, 22, 30, 33,  2, 12, 22,  2, 33, 30, 12,  8,  8, 14, 22, 35, 35,  2,\n",
            "         8,  2,  1, 30, 22,  2, 33, 35, 30, 33, 33,  8, 14, 14],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([ 1, 22, 30, 22,  1, 12, 12,  2, 12, 30, 33, 12, 22,  2, 12,  8,  2, 22,\n",
            "        33, 23, 22, 22,  1, 23, 35, 14, 22, 23, 12, 35, 12,  8],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([ 1, 22, 30, 22,  1, 12, 12,  2, 14, 30, 33, 12, 22,  2, 33,  8,  2, 22,\n",
            "        33, 23, 22, 22,  1, 23, 35, 14, 22, 14, 12, 35, 33,  8],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([12, 14, 35,  8,  1, 22, 33, 12, 33,  2, 35,  1, 35, 35, 35,  1, 33, 12,\n",
            "        23,  1, 35,  1,  1, 30,  1, 12, 33, 14,  1, 35, 22, 23],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([12, 14, 35,  8,  1, 22, 33, 12, 33,  2, 35,  2, 35, 35, 35,  1, 33, 12,\n",
            "        23,  1, 35,  1,  1, 30,  1, 12, 33, 14,  1, 35, 22, 23],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([33, 30, 30, 22,  2, 12, 23, 22, 30, 35, 30, 14, 22, 35, 23, 22, 30, 35,\n",
            "        22,  2, 22, 12, 30, 12,  2, 22, 12,  8, 33, 33,  8,  8],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([33, 30, 30, 22,  2, 12, 23, 22, 30, 35, 30, 14, 22, 35, 23, 22, 30, 35,\n",
            "        22,  2, 22, 12, 30, 12,  2, 22, 12,  8, 33, 33,  8,  8],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([22, 22, 35,  2, 33, 33, 14, 35, 33, 30, 30,  2,  1, 33, 33, 35, 30, 22,\n",
            "         2,  1,  2, 33, 23,  2,  8,  8, 23, 33, 12, 12, 30, 33],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([22, 22, 35,  2, 33, 33, 14, 35, 33, 30, 30,  2,  1, 33, 33, 35, 30, 22,\n",
            "         2,  1,  2, 33, 14,  2,  8,  8, 23, 33, 12, 12, 30, 12],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([ 1, 35, 23,  8, 23, 14, 22,  2,  8, 30, 30, 33, 23,  8, 14,  8, 33, 12,\n",
            "         8,  2, 33, 22, 22,  1, 22, 30,  8, 30,  2, 12, 14,  1],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([ 1, 35, 23,  8, 23, 14, 22,  2,  8, 30, 30, 12, 23,  8, 12,  8, 33, 12,\n",
            "         8,  2, 33, 22, 22,  1, 22, 30,  8, 30,  2, 12, 14,  1],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([30, 30, 35,  2, 23, 33, 14, 33, 14, 33, 35, 14, 30, 35,  8,  8,  8, 14,\n",
            "        30,  2, 30,  2, 23, 35, 12, 35, 33,  8, 14, 12, 33,  8],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([30, 30, 35,  2, 23, 33, 14, 33, 14, 33,  1, 14, 30, 35,  8,  8,  8, 14,\n",
            "        30,  2, 30,  2, 14, 35, 12, 35, 33,  8, 14, 12, 33,  8],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([14, 35, 33, 33,  2, 22, 30,  8, 35, 33,  2, 23, 33, 35, 14,  2, 22, 23,\n",
            "        30, 22, 12,  8,  2, 30, 22, 12,  2,  2,  2, 23,  2, 23],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([14, 35, 33, 33,  2, 22, 30,  8, 35, 33,  2, 23, 33, 35, 14,  2, 22, 14,\n",
            "        30, 22, 12,  8,  2, 30, 22, 33,  2,  2,  2, 23,  2, 14],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([14, 14,  8, 33, 23, 33,  8,  2,  2, 23, 30,  1, 33, 30, 14, 12, 23, 33,\n",
            "        22, 30, 22,  2, 14, 14, 30, 30, 30, 23, 22,  8, 12, 23],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([14, 14,  8, 33, 14, 33,  8,  2,  2, 23, 30,  1, 33, 30, 14, 12, 23, 23,\n",
            "        22,  2, 22,  2, 14, 14, 30, 30, 30, 23, 22,  8, 12, 23],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([35, 35,  8, 30, 35,  2, 35, 14, 14, 30,  8,  2, 23, 30,  8,  2,  2, 23,\n",
            "        33, 23, 30,  2, 22, 35, 23, 12,  8, 33,  2, 22, 14, 30],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([35, 35,  8, 30, 35,  2, 35, 14, 14, 30,  8, 33, 23, 30,  8,  2,  2, 23,\n",
            "        33, 23, 30,  2, 22, 35, 14, 23,  8, 33,  2, 22, 14, 30],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([23, 12, 23,  2,  1, 12, 22, 12, 22, 22, 14,  1, 30, 30, 12, 35, 30, 30,\n",
            "        12, 30, 22, 30, 35, 14, 12,  2,  1, 35,  2, 30,  2,  2],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([23, 33, 23,  2,  1, 12, 22, 12, 22, 22, 14,  1, 30, 30, 12, 35, 35, 30,\n",
            "        12, 30, 22, 30, 35, 14, 23,  2,  1, 35,  2, 30,  2,  2],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([23, 14,  2, 30, 35,  8,  2, 33, 23, 30,  2, 30, 23, 23, 30,  1,  1, 14,\n",
            "        12, 12,  2, 23,  2, 22,  8, 22, 12, 33, 30, 33,  8, 22],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([23, 23,  2, 30, 35,  8,  2, 12, 23, 30,  2, 30, 14, 23, 30,  1,  1, 23,\n",
            "        12, 12,  2, 23,  2, 22,  8, 22, 12, 33, 30, 12,  8, 22],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([23,  8, 14, 14, 30, 23, 33, 14, 14, 30, 12,  2, 12, 12,  2, 35, 35, 35,\n",
            "        30,  2,  1, 33, 33, 30, 22, 22,  2,  2,  8, 30, 35, 22],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([14,  8, 14, 23, 30, 23, 33, 14, 14, 30, 12,  2, 12, 23,  2, 35, 35, 35,\n",
            "        30,  2,  1, 33, 33, 30, 22, 22,  2,  2,  8, 30, 35, 22],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([14, 14, 12, 12,  2, 23, 35,  2,  2, 23, 23, 14, 35, 23,  8, 23, 12, 33,\n",
            "         2,  1, 30, 12, 22,  2, 30, 22, 23, 12,  2, 23, 30, 14],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([14, 14, 12, 12,  2, 23, 35,  2,  2, 23, 23, 14, 35, 23,  8, 33, 12, 33,\n",
            "        30,  1, 30, 12, 22,  2, 30, 22, 23, 12,  2, 14, 30, 14],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([35, 33,  8,  1, 33,  2, 35, 23, 22, 23, 12,  2,  8,  2, 22, 35, 33, 30,\n",
            "        22, 22,  8,  8, 33,  8,  8, 35, 12, 23,  2, 23, 12, 14],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([35, 33,  8,  1, 33,  2, 35, 23, 22, 23, 12,  2,  8,  2, 22, 35, 33, 30,\n",
            "        22, 22, 12,  8, 33,  8,  8, 35, 12, 23,  2, 23, 12, 14],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([ 1, 33, 30,  8,  8, 14, 14, 22, 22, 22,  8, 14, 33, 14, 23, 22,  2,  8,\n",
            "        14,  8, 23, 35, 14, 33, 22, 22, 33, 22,  8, 12, 23, 14],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([ 1, 33, 30,  8,  8, 14, 14, 22, 22, 22,  8, 14, 33, 14, 23, 22,  2,  8,\n",
            "        14,  8, 23, 35, 14, 33, 22, 22, 33, 22,  8, 12, 23, 14],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([ 2, 33, 33, 22, 22, 14,  8,  8,  8, 33, 35, 23, 14, 14, 33,  1,  8, 30,\n",
            "        30, 30,  2, 12, 14, 12, 23, 35, 12, 12,  1,  2, 30, 12],\n",
            "       device='cuda:0')\n",
            "PREDS: tensor([ 2, 33, 33, 22, 22, 14,  8,  8,  8, 33, 35, 23, 14, 14, 33,  1,  8, 30,\n",
            "        30, 30,  2, 23, 14, 30, 23, 35, 12, 12,  1,  2, 30, 33],\n",
            "       device='cuda:0')\n",
            "LABELS: tensor([23,  1,  8, 12, 35,  1, 33, 33, 30,  8, 30,  2], device='cuda:0')\n",
            "PREDS: tensor([14,  1,  8, 12, 35,  1, 33, 33, 30,  8, 30,  2], device='cuda:0')\n",
            "Test 1, loss: 1.438663, test acc: 0.925110, test avg acc: 0.923349\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNY4KT4rt6ZD",
        "outputId": "501f1848-98c9-4c20-ebbd-0685eac165c0"
      },
      "source": [
        "!python3 main.py --exp_name=dgcnn_1024 --model=dgcnn --num_points=1024 --k=20 --epochs=250 --use_sgd=True --test_batch_size=18 --classifycustom"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(batch_size=32, classify_mode_custom=True, classify_mode_mixed=False, dataset='modelnet40', dropout=0.5, emb_dims=1024, epochs=250, eval=False, eval_custom=False, eval_mixed=False, exp_name='dgcnn_1024', k=20, lr=0.001, model='dgcnn', model_path='', momentum=0.9, no_cuda=False, num_points=1024, seed=1, test_batch_size=18, train_custom=False, use_sgd=True)\n",
            "Using GPU : 0 from 1 devices\n",
            "Namespace(batch_size=32, classify_mode_custom=True, classify_mode_mixed=False, cuda=True, dataset='modelnet40', dropout=0.5, emb_dims=1024, epochs=250, eval=False, eval_custom=False, eval_mixed=False, exp_name='dgcnn_1024', k=20, lr=0.001, model='dgcnn', model_path='', momentum=0.9, no_cuda=False, num_points=1024, seed=1, test_batch_size=18, train_custom=False, use_sgd=True)\n",
            "['to_classify/monitor.pt', 'to_classify/chair.pt', 'to_classify/stuhl.pt', 'to_classify/tisch.pt']\n",
            "filename:  monitor\n",
            "predicted class: Nr.:  22\n",
            "predicted class: Name:  monitor \n",
            "\n",
            "Logits:  tensor([[ 0.0352, -0.6263, -0.6011,  0.0364,  0.0418,  0.0353,  0.0357,  0.0351,\n",
            "         -0.0789,  0.0359,  0.0356,  0.0380, -1.4807,  0.0387, -0.7791,  0.0337,\n",
            "          0.0349,  0.0344,  0.0345,  0.0346,  0.0362,  0.0386,  5.2542, -1.1812,\n",
            "          0.0362,  0.0352,  0.0389,  0.0342,  0.0372,  0.0381, -0.6343,  0.0358,\n",
            "          0.0327,  0.2938,  0.0355, -1.4998,  0.0353,  0.0347,  0.0366,  0.0337]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>) \n",
            "\n",
            "filename:  chair\n",
            "predicted class: Nr.:  8\n",
            "predicted class: Name:  chair \n",
            "\n",
            "Logits:  tensor([[ 0.1654, -0.7182, -1.0277,  0.1648,  0.1736,  0.1663,  0.1694,  0.1687,\n",
            "          5.6317,  0.1592,  0.1666,  0.1631, -2.2312,  0.1724, -0.3651,  0.1666,\n",
            "          0.1602,  0.1698,  0.1680,  0.1685,  0.1643,  0.1681, -0.9130, -2.7351,\n",
            "          0.1626,  0.1665,  0.1668,  0.1608,  0.1697,  0.1690, -2.0585,  0.1676,\n",
            "          0.1695, -0.1142,  0.1664, -0.6323,  0.1633,  0.1653,  0.1686,  0.1657]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>) \n",
            "\n",
            "filename:  stuhl\n",
            "predicted class: Nr.:  8\n",
            "predicted class: Name:  chair \n",
            "\n",
            "Logits:  tensor([[-0.1312,  0.2784, -0.6631, -0.1317, -0.1313, -0.1345, -0.1304, -0.1344,\n",
            "          4.6837, -0.1324, -0.1322, -0.1296,  0.1902, -0.1319, -0.1236, -0.1320,\n",
            "         -0.1341, -0.1343, -0.1313, -0.1300, -0.1314, -0.1341, -0.0171, -1.2297,\n",
            "         -0.1352, -0.1367, -0.1315, -0.1328, -0.1317, -0.1332, -0.8702, -0.1352,\n",
            "         -0.1313,  1.0852, -0.1310,  0.6411, -0.1339, -0.1342, -0.1321, -0.1301]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>) \n",
            "\n",
            "filename:  tisch\n",
            "predicted class: Nr.:  33\n",
            "predicted class: Name:  table \n",
            "\n",
            "Logits:  tensor([[-0.0679, -0.4011, -0.9005, -0.0684, -0.0676, -0.0657, -0.0669, -0.0660,\n",
            "          0.4500, -0.0659, -0.0607, -0.0630, -0.7316, -0.0687, -0.7151, -0.0617,\n",
            "         -0.0628, -0.0659, -0.0650, -0.0667, -0.0615, -0.0678, -0.0570, -0.5185,\n",
            "         -0.0631, -0.0672, -0.0658, -0.0649, -0.0677, -0.0658,  0.3982, -0.0621,\n",
            "         -0.0648,  5.1427, -0.0647, -0.4987, -0.0641, -0.0641, -0.0635, -0.0660]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_kwpa8GVs7nt",
        "outputId": "2ed37cce-0a57-4d65-d77e-dce2a8e4e59c"
      },
      "source": [
        "#Download for the classificators main files in case you have made any changes\r\n",
        "\r\n",
        "from google.colab import files\r\n",
        "\r\n",
        "files.download(\"/content/dgcnn/pytorch/data.py\")\r\n",
        "files.download(\"/content/dgcnn/pytorch/main.py\")\r\n",
        "files.download(\"/content/dgcnn/pytorch/model.py\")\r\n",
        "files.download(\"/content/dgcnn/pytorch/util.py\")\r\n",
        "files.download(\"/content/dgcnn/pytorch/singfpass.py\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a0f498ee-f889-4867-ba89-0752b3cfc517\", \"data.py\", 6004)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_379f8f2f-d6e7-4edf-9a7f-06f6a14d1b34\", \"main.py\", 22380)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_ec379860-7376-4ac0-835a-a39db1923cdc\", \"model.py\", 5458)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_01e61b2f-164f-4d6b-8057-1fd4bc07ca4f\", \"util.py\", 995)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_8262d9ce-745f-478f-9d12-224053b4b34a\", \"singfpass.py\", 1842)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}